from enum import auto, IntEnum
{% if not ast -%}
from typing import List, Optional, Protocol, Union
{% else -%}
from typing import Protocol
{%- endif %}

class TokenType(IntEnum):
    """
    All token types as found in the grammar
    """
{% for tt in token_types %}
    {{ tt }} = auto()
{%- endfor %}

{% if not ast %}
class TreeNode(Protocol):
    """
    Represents a single node in the parse tree. It is implemented by 'Token'
    as well as any objects emitted by non-terminal parser rules.
    """

    nodes: List[Union[Optional["TreeNode"], List["TreeNode"]]]


class Token(TreeNode):
{% else %}
class Token(Protocol):
{%- endif %}
    """
    Represents a single token emitted by the lexer and consumed by the parser
    """

    token_type: TokenType


class Tokenizer(Protocol):
    """
    The interface required of the lexer that is consumed by the parser
    """

    def next_token(self) -> Token:
        ...

